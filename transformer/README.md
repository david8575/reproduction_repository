# Transformer Implementation

## ğŸ“– Paper
### Attention Is All You Need
- https://arxiv.org/abs/1706.03762

## ğŸš€ Features
- ë…¼ë¬¸ê³¼ ë™ì¼í•œ ì•„í‚¤í…ì²˜ êµ¬í˜„
- RTX 3090 ìµœì í™”
- WMT 2014 English-German ë°ì´í„°ì…‹ ì§€ì›
- BLEU ì ìˆ˜ ë° Perplexity ì¸¡ì •

## ğŸ“ Project Structure
```
transformer/
â”œâ”€â”€ model/                          # Transformer ëª¨ë¸ êµ¬í˜„
â”‚   â”œâ”€â”€ blocks/                     # Encoder/Decoder ë¸”ë¡
â”‚   â”œâ”€â”€ embeddings/                 # Token ë° Positional Embedding
â”‚   â”œâ”€â”€ layers/                     # Attention, FFN, Residual Connection
â”‚   â”œâ”€â”€ models/                     # ì „ì²´ ëª¨ë¸ êµ¬ì¡°
â”‚   â””â”€â”€ make_model.py               # ëª¨ë¸ ìƒì„± íŒ©í† ë¦¬
â”œâ”€â”€ data/                           # ë°ì´í„° ì²˜ë¦¬
â”‚   â”œâ”€â”€ download_wmt.py             # WMT ë°ì´í„° ë‹¤ìš´ë¡œë“œ
â”‚   â””â”€â”€ preprocess.py               # ë°ì´í„° ì „ì²˜ë¦¬
â”œâ”€â”€ utils/                          # ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ metrics.py                  # BLEU, Perplexity ê³„ì‚°
â”‚   â””â”€â”€ visualization.py            # Attention ê°€ì¤‘ì¹˜ ì‹œê°í™”
â”œâ”€â”€ config.py                       # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
â”œâ”€â”€ train.py                        # ë©”ì¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ requirements.txt                # í•„ìš”í•œ íŒ¨í‚¤ì§€
```

## ğŸ› ï¸ Installation

### 1. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ë˜ëŠ”
.venv\Scripts\activate     # Windows
```

### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

## ğŸš€ Usage

### 1. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ (CPU/GPU)
```bash
python -m model.make_model
```

### 2. WMT ë°ì´í„° ë‹¤ìš´ë¡œë“œ
```bash
python data/download_wmt.py
```

### 3. ì „ì²´ í•™ìŠµ (RTX 3090 ê¶Œì¥)
```bash
python train.py
```

## âš™ï¸ Configuration

ë…¼ë¬¸ê³¼ ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°:
- **d_model**: 512
- **d_ff**: 2048
- **n_layers**: 6
- **n_heads**: 8
- **batch_size**: 128
- **learning_rate**: 0.0001

## ğŸ“Š Expected Performance (RTX 3090)

- **í•™ìŠµ ì†ë„**: CPU ëŒ€ë¹„ 15-20ë°° ë¹ ë¦„
- **ë°°ì¹˜ í¬ê¸°**: 128 (ë…¼ë¬¸ê³¼ ë™ì¼)
- **ë©”ëª¨ë¦¬**: 24GB VRAMìœ¼ë¡œ ì¶©ë¶„
- **í•™ìŠµ ì‹œê°„**: WMT ë°ì´í„° ê¸°ì¤€ 1-2ì¼

## ğŸ” Testing

### CPU/GPU í…ŒìŠ¤íŠ¸
```bash
python -m model.make_model
```

### Attention ê°€ì¤‘ì¹˜ ì‹œê°í™”
```python
from utils.visualization import plot_attention_weights
# ì‚¬ìš© ì˜ˆì‹œ
```

### BLEU ì ìˆ˜ ê³„ì‚°
```python
from utils.metrics import calculate_bleu
# ì‚¬ìš© ì˜ˆì‹œ
```

## ğŸ“ Notes

- RTX 3090ì—ì„œ ìµœì  ì„±ëŠ¥ì„ ìœ„í•´ ì„¤ê³„ë¨
- ë…¼ë¬¸ì˜ ì •í™•í•œ êµ¬í˜„ì„ ëª©í‘œë¡œ í•¨
- WMT 2014 ë°ì´í„°ì…‹ìœ¼ë¡œ ê²€ì¦ ê°€ëŠ¥

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request